# 3.2 메모리

> **무어의 법칙** : 대량 생산한 칩상의 트랜지스터 수는 약 18개월마다 2배씩 증가한다.

무어의 법칙에 따라 개수가 증가한 트랜지스터는 **클록 속도의 향상**, **프로세서 속도 증가**를 이끌어냈다. 오히려 메모리가 프로세서의 데이터 수요를 맞추기 어려워지는 상황 발생. 프로세서의 데이터 수요를 맞추기 위해 CPU Cache를 사용함.

CPU Cache는 RAM 보다 **10~100배** 빠른 접근 속도를 가지고 CPU Request에 응답하는데 **몇 ns**밖에 소요되지 않는다.

<img width="300" alt="스크린샷 2024-01-10 오후 2 00 54" src="https://github.com/CMC11th-Melly/Melly_Server/assets/82302520/a40a3173-1c7b-44f9-a961-545573f3b85a">

- **L1 Cache**
    - CPU에서 가장 가까운 캐시. CPU Core 내에 위치하고 있다.
    - High End CPU(intel i9)의 경우 1MB 크기의 L1 Cache를 가지고 있다. 보통은 KB 단위의 사이즈.
    - 평균적으로 RAM보다 100배 정도 빠르다.
    - L1 Cache는 두 섹션(Instruction, Data)으로 분리되어 있음. Instruction에서는 CPU 연산과 관련된 정보를 포함하고 있고, Data는 연산에 필요한 데이터를 보관하고 있다.
- **L2 Cache**
    - L2 Cache도 L1 Cache와 마찬가지로 CPU Core 내에 위치하고 있다.
    - 보통 MB 단위의 사이즈를 가진다.
    - 평균적으로 RAM보다 20배 정도 빠르다.
- **L3 Cache**
    - CPU 칩 내의 코어들이 모두 공유하는 Cache
    - 예전에는 L3 Cache는 마더보드에 위치했지만 Modern CPU는 L3 Cache가 CPU 내에 존재한다. L1,L2는 칩 내 각각의 코어에 위치하지만 L3는 코어 외부에 위치하는게 특징.
    - 종류에 따라 100MB 정도까지 사이즈가 커지기도 한다.

### 캐시 일관성 프로토콜

CPU Cache를 도입해서 프로세서 처리율은 향상됐지만, 메모리와 CPU Cache 사이의 데이터 일관성이 문제가 됐다. 이를 해결하기 위해 **캐시 일관성 프로토콜** 사용.

**MESI 프로토콜**
- Modified : 데이터가 수정된 상태
- Exclusive : 이 캐시에만 데이터가 존재하고 메모리 내용과 동일한 상태
- Shared : 둘 이상의 캐시에 데이터가 들어있고 메모리 내용과 동일한 상태
- Invalid : 다른 프로세스가 데이터를 수정하여 무효한 상태

> 멀티 프로세서가 Shared 상태에 있다가 하나의 프로세서가 Modified나 Exclusive 상태로 변경되면 브로드캐스트를 통해 다른 Cache가 Invalid 상태로 비워진다. 이 방식으로 CPU Cache간 데이터 일관성 확보

프로세서 처음 등장시에는 **Write-Through** 방식을 통해 캐시 연산 결과 바로 메모리에 기록. 이 방식은 메모리 대역폭을 많이 소모해서 효율이 낮음.

최근에는 **Write-Back** 방식을 사용해서 캐시 블록을 교체해도, 변경된 블록만 선별적으로 메모리에 기록해서 메인 메모리 대역폭 사용 감소.



# 3.3 최신 프로세서의 특성

### TLB
가상 메모리 주소를 물리 메모리 주소로 매핑하는 페이지 테이블의 캐시 역할 수행

- **TLB의 위치** : CPU의 MMU 내에 위치
- **TLB를 사용하는게 빠른 이유** : 물리 메모리에 액세스 하는 횟수가 다르다. TLB를 사용할때 TLB Hit이 발생한다면 물리 메모리 접근은 1회 발생한다. 하지만, TLB를 사용하지 않으면 메모리의 page table 접근 1회, 실제 물리 메모리 접근 1회, 최소 2회가 발생한다. 최소 2회인 이유는 보통 page table이 layered로 구성되기 때문에 layer의 수에 따라서 메모리 액세스 횟수가 증가한다.
- TLB는 보통 보통 32-1024개의 entries를 포함한다.
- TLB 접근 시간 **1ns**, 메인 메모리 는 **100ns** 정도 소요

<details>
<summary>페이지 테이블 추가 학습</summary>
<div markdown="1">

<br/>

페이지 테이블 내부는 PTE(Page Table Entries)로 구성. Map의 Entry와 같다. 각각의 PTE의 크기는 **4bytes**이다.
각각의 어플리케이션이 Page Table을 가지기 때문에 페이지 테이블 개수가 증가하면 나중에는 메모리 부족으로 페이지 테이블이 Disk Swap 될 수도 있음. 따라서 **Multi Level Page Table**을 사용해서 하나의 페이지 테이블을 몇 단계로 나눈 후 당장 불필요한건 미리 Disk Swap 해 둘 수 있다.

운영체제의 요구 페이징 기법과 비슷한 원리
</div>
</details>



- [Multi Layer Page Table 참고](https://www.baeldung.com/cs/multi-level-page-tables)

### 분기 예측과 추측 실행

**비순차 실행**
- 프로그래머가 작성한 명령어를 순차적으로 실행할때 앞의 명령어가 데이터를 읽어오는데 시간이 걸려 CPU가 놀 것 같으면 뒤의 명령어 중 앞의 명령어에 영향을 미치지 않는걸 먼저 실행한다.

**추측 실행**
```java
if (x > 10) 
    y = 3
```
y에 3을 대입하는 연산은 x > 10이 true일때 이뤄져야 한다. 만약 어떤 이유로 x 값을 읽어오는데 시간이 걸린다고 하면
CPU는 y = 3을 미리 계산해둔다. 만약 x > 10이 참이면 그대로 진행. 아니면 y = 3 폐기

이러한 특성으로 인해 여러 보안 문제들이 발생함 (ex. 커널 접근 권한이 있어야 접근 가능한 영역을 CPU가 권한 체크 전 비순차 실행으로 유저모드에서 접근)

- [참고 유튜브](https://www.youtube.com/watch?v=Npd77X1MTAo)
- [참고 블로그](https://medium.com/@kjhcloud/%EC%9D%B8%ED%85%94-cpu-%EC%B7%A8%EC%95%BD%EC%A0%90-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-9ddab8d502b7)

# 3.4 운영체제

**OS의 주 임무** : 여러 실행 프로세스에 **한정된 시스템 리소스를 분배**하고, 프로세스로부터 **시스템 리소스를 보호**. 여러 시스템 리소스 중 메모리와 CPU가 특히 중요함.

MMU(Memory Management Unit)을 통한 가상 주소 방식과 페이지 테이블은 **메모리 엑세스를 제어**하고 프로세스 간 **영역 침범을 방지**하는 중요한 기능이다.

> 만약 가상 메모리 공간을 사용하지 않을 때 발생할 수 있는 문제점은?

프로세스가 물리 메모리를 직접 사용하면 시스템에 치명적인 문제들이 발생한다.
1. 하나의 프로세스가 대부분의 물리 메모리를 다 사용 가능
2. 물리 메모리 공간이 부족해서 여러 프로세스를 동시에 실행 불가
2. 하나의 프로세스가 다른 프로세스 영역 침범 가능
3. 프로세스가 동작 중 죽으면 메모리 회수 못한다. 해당 메모리를 회수하기 위해서는 시스템 재부팅이 필요

가상 주소 기반 가상 메모리를 사용하게 되면 메모리 할당/해제 권한을 운영체제가 소유하게 된다.

물리 메모리 크기 이상의 프로세스들을 실행할 수 있고, 프로세스가 죽을 시 운영체제가 할당된 물리 메모리를 바로 회수할 수 있음.

### 스케쥴러

프로세스 스케줄러는 CPU 액세스를 통제한다. 프로세스가 CPU를 할당 받고 작업을 수행하다가 할당 시간이 끝나면 CPU를 반납하고 실행 큐(run queue)로 돌아가서 CPU 재할당을 기다린다.

```java
long start = System.currentTimeMillis();
for(int i =0; i < 1_000; i < i++){
  Thread.sleep(1);    
}
long end = System.currentTimeMillis();
System.out.println("Millis elapsed: " + (end-start) / 4000.0);
```
위의 코드는 Thread를 1ms씩 총 1000번 sleep을 건다. 직관적으로는 총 1초가 수행되야 하지만, 실행 큐에 들어가서 대기하는 시간으로 인해 스케쥴링 오버헤드가 발생함.


### 컨텍스트 스위치

**컨텍스트 스위치** : OS 스케쥴러가 현재 실행 중인 스레드/태스크를 없애고 대기 중인 다른 스레드/태스크로 대체하는 과정

여러 컨텍스트 스위칭 중 **모드 전환 컨텍스트 스위칭** 비용이 큼.

> **모드 전환** : 유저 영역에서 시스템 콜을 호출하면 커널 모드로 전환

유저 공간과 커널 공간은 공유하는 메모리 영역이 다르기 때문에 전환 과정에서 컨텍스트를 초기화 하는 과정이 필요.

CPU에는 TLB라는 페이지 테이블 캐시가 존재하고 CPU가 물리 메모리의 어느 부분에 접근해야 하는지 캐싱되있음. 모드 전환이 되면 참조하는 영역이 아예 달라지기에 TLB를 초기화해야 한다.

TLB가 초기화 되면 **RAM 액세스 횟수가 증가**하기 때문에 **시스템 지연시간이 증가**한다.

### vDSO

**vDSO** : 커널 프리빌리지가 필요 없는 시스템 콜의 경우 커널 모드로 컨텍스트 스위칭 하지 않기 위해 사용되는 유저 메모리 영역

원래는 커널 자료 구조를 읽어서 시스템 클록 시간을 얻어와야 하지만, vDSO로 **유저 주소 공간에 매핑** 시키면 커널 모드로 전환 필요 없음.


# 3.5 단순 시스템 모델
시스템 모델은 다음의 기본 컴포넌트들로 구성
- 애플리케이션이 실행되는 OS와 하드웨어
- 애플리케이션이 실행되는 JVM/컨테이너
- 애플리케이션 코드
- 애플리케이션이 호출하는 외부 시스템
- 애플리케이션으로 유입되는 트래픽

## CPU 사용률
- CPU 사용률은 애플리케이션 성능을 나타내는 핵심 지표
- 부하가 집중되는 경우에 CPU 사용률은 가능한 100%에 가까워야 한다
    - CPU가 효율적으로 사용되지 못하는 경우, 코드 상에 비효율적인 부분이 있거나 데드락이 발생했는지 체크 필요
- CPU 사용률은 `vmstat`이나 `top` 명령어를 사용해서 체크 가능

### vmstat
리눅스에서 시스템 지표를 분석할 수 있는 가장 기본적인 툴

| 섹션     | 지표   | 설명                     | 분석                                        |
|--------|------|------------------------|-------------------------------------------|
| proc   | r    | 실행 가능 프로세스             | 해당 값이 CPU 코어보다 크면 병목 발생 상황                |
| proc   | b    | 블로킹된 프로세스              |                                           |
| memory | swpd | 스왑 메모리                 |                                           |
| memory | free | 미사용 메모리                | 해당 영역이 부족하면 디스크 스왑 발생                     |
| memory | buff | 버퍼로 사용되는 메모리           |                                           |
| memory | cache | 페이지 캐시                 | Disk I/O를 줄이기 위해 데이터를 메모리에 캐시             |
| swap   | si   | 초당 디스크에서 메모리로 스왑인 된 횟수 |                                           |
| io     | bi   | I/O 장치에서 들어온 블록 개수     | 수치가 높으면 Disk I/O가 많이 발생하고 있는 상황           |
| io     | bo   | I/O 장치로 나간 블록 개수       |                                           |
| swap   | so   | 초당 메모리에서 디스크로 스왑아웃 된 횟수 | 해당 지표가 높으면 가용 메모리가 부족한 상태                 |
| system | in   | 초당 인터럽트 횟수             |                                           |
| system | cs   | 초당 컨텍스트 스위칭 횟수         | CPU 사용률이 낮은데 해당 수치 높으면 I/O 블로킹이나 쓰레드 경합 의심 |
| cpu    | us   | 유저 영역 CPU 사용률          | 부하가 없는 상황에서 CPU 사용률 높으면 비효율적 코드(무한루프) 의심  |
| cpu    | sy   | 커널 영역 CPU 사용률          |                                           |

### CPU 문제 상황 예시

CPU Intensive한 어플리케이션은 CPU 사용률 100%를 목표로 해야 함. CPU 사용률이 100%가 아니라면 원인 분석 필요.
- 유저 공간에서 CPU 사용률 100%가 아닌데 컨텍스트 스위칭 횟수가 높으면 **I/O 블로킹**이나 **스레드 락 경합** 의심 필요
    - 스레드가 락을 획득하기 위해 blocking되면 CPU를 들고 있지 않고 컨텍스트 스위칭 발생

스레드 상태를 실시간으로 분석하기 위해서는 **VisualVM** 같은 프로그램 추가 사용 필요


# 3.7 가상화

가상화의 대표적인 방식은 실행 중인 Host OS 위에 Guest OS를 하나의 프로세스로 실행시키는 방식.

- 가상화 OS에서 실행하는 프로그램은 베어 메탈에서 실행할때랑 동일하게 작동해야 함
    - 가상화 OS의 하드웨어(Virtual NIC)는 Host OS의 NIC로 포워딩 되기 때문에 인터넷 정상 접속 됨
- 하이퍼바이저가 모든 하드웨어 리소스 액세스를 조정함
    - Host OS 위에 하이퍼바이저가 올려지는 구조를 호스트 하이퍼바이저라고 함
- 가상화 오버헤드는 가급적 작아야 함

가상화 OS는 직접 하드웨어 자원에 접근 불가능하기에 **언프리빌리지드 명령어**를 주로 사용.


<details>
<summary>가상화와 컨테이너 차이</summary>
<div markdown="1">


<img width="500" alt="스크린샷 2024-01-06 오후 11 43 41" src="https://github.com/CMC11th-Melly/Melly_Server/assets/82302520/ca867fbd-b494-4c3a-a88f-c3ff05dde358">

**가상 머신**
- 가상 머신마다 독립적인 Guest OS를 구축
- 하드웨어(ex.Network Interface Card)를 소프트웨어로 가상화
- 하이퍼바이저가 하드웨어 리소스 액세스를 조정해서 가상 머신에 제공

**컨테이너**
- 가상 머신에서 Guest OS와 가상 하드웨어를 제거
- 어플리케이션 코드와 실행에 필요한 바이너리들만 Wrapping해서 컨테이너로 생성
- 어플리케이션 실행에 필요한 리소스는 도커 엔진이 Host OS로부터 얻어와서 제공

가상 머신 위에서 동작하는 어플리케이션 하나를 위해 Guest OS와 가상 하드웨어를 구축하는게 리소스의 낭비라는 관점에서 컨테이너가 출발

또한 가상 머신은 Guest OS와 가상 하드웨어 모두 **개별 프로세스로 동작한다**. 가상 머신의 개수가 늘어나면 그만큼 실행되는 프로세스가 증가하고 과도한 리소스 사용으로 인해 Host OS의 성능에 영향을 미친다.

컨테이너는 OS와 가상 하드웨어를 제거함으로써 Host의 리소스 부담을 획기적으로 줄였다.


</div>
</details>




# 3.8 JVM과 운영체제

- JVM은 공용 인터페이스(Common Interface)를 제공하여 **OS에 독립적인** 실행 환경 제공

- 스레드 관련 작업들은 모두 하부 OS에 반드시 액세스 해야 하고, **native 키워드**를 붙인 네이티브 메서드로 구현 가능


native 키워드를 붙인 작업은 OS에 시스템 콜을 호출해서 커널 모드로 작업을 수행. 네이티브 메서드는 C언어로 작성했고 JNI(Java Native Interface)가 네이티브 메서드를 자바 메서드처럼 액세스 함.

### 예시

`System.currentTimeMillis()`가 실행되는 과정을 살펴보자. 해당 메서드는 native 키워드를 사용함

```java
public static native long currentTimeMillis(); // System.currentTimeMillis() 자체가 native 메서드
```

1. currentTimeMillis()는 JVM_CurrentTimeMillis()라는 JVM 엔트리 포인트 메서드에 매핑. java/lang/System.c 파일에 해당 정보가 매핑됨.
2. JVM_CurrentTimeMillis()가 os::javaTimeMillis()를 호출. OpenJDK의 os별 코드 디렉토리에 존재함.


<details>
<summary>Java Thread의 native method 사례</summary>
<div markdown="1">

<br/>

- Java Thread는 Platform Thread로 OS Thread와 **일대일 매핑** 구조를 가짐.
- Java Thread 객체 생성 이후의 모든 작업 권한(ex. 쓰레드 스케쥴링)은 OS에게 넘어감.

간단한 Thread 실행 예시를 살펴보자
```java
public class ThreadExample {
    public static void main(String[] args) {

        MyRunnable task = new MyRunnable();
        Thread thread = new Thread(task);
        thread.start(); // start() 실행시 내부적으로 native method 사용
    }
}

class MyRunnable implements Runnable{

    @Override
    public void run() { // OS 쓰레드 매핑 후 run() 메서드 실행
        System.out.println("Thread Start...");
    }
}
```

Thread 객체를 생성할때 runnable을 인자로 넘겨주고 start()를 통해 쓰레드 실행 가능하다. start() 메서드를 디버깅 해보자.

<img width="400" alt="스크린샷 2024-01-06 오후 11 43 41" src="https://github.com/CMC11th-Melly/Melly_Server/assets/82302520/86f6dc35-0e82-40cf-b8a1-cae6c803b316">


start() 메서드 내부를 보면 `start0()` 메서드가 존재한다.

start0()는 native method로써 시스템 콜을 호출해서 OS Thread를 생성 후 Java Thread와 매핑한다. 이후 run()을 호출해서 쓰레드 작업을 실행한다.

> run()을 직접 호출하면 어떻게 될까?

run()을 직접 호출하면 새로운 쓰레드가 아닌 **main 쓰레드**가 일반 메서드 호출과 똑같이 실행한다. 새로운 쓰레드는 생성되지 않기 때문에 반드시 `start()`를 호출해야 한다.


</div>
</details>

